{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50995688-2279-4fb6-b85b-906938af9dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # 운영 체제와 상호작용하기 위한 os 모듈 임포트\n",
    "import tempfile  # 임시 파일 생성을 위한 tempfile 모듈 임포트\n",
    "import logging  # 로그 메시지를 위한 logging 모듈 임포트\n",
    "from flask import Flask, request, jsonify  # 웹 애플리케이션 생성을 위한 Flask와 유틸리티 임포트\n",
    "import whisper  # Whisper ASR 모델 임포트\n",
    "import torch  # 텐서 연산을 위한 PyTorch 임포트\n",
    "import threading  # 스레드를 생성하기 위한 threading 모듈 임포트\n",
    "import queue  # 작업 큐 생성을 위한 queue 모듈 임포트\n",
    "import uuid  # 고유한 작업 ID 생성을 위한 uuid 모듈 임포트\n",
    "\n",
    "# 로그 메시지를 info 레벨로 설정\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)  # 이 모듈을 위한 로거 생성\n",
    "\n",
    "app = Flask(__name__)  # Flask 애플리케이션 인스턴스 생성\n",
    "\n",
    "# 작업 큐와 결과 저장을 위한 딕셔너리 초기화\n",
    "task_queue = queue.Queue()\n",
    "results = {}\n",
    "\n",
    "# 오디오 파일을 처리할 작업자 스레드 수 설정\n",
    "num_worker_threads = 4\n",
    "\n",
    "# 오디오 파일을 처리할 작업자 함수 정의\n",
    "def worker(thread_id):\n",
    "    logger.info(f\"Worker {thread_id} starting, loading Whisper model...\")\n",
    "    whisper_model = whisper.load_model(\"medium\")  # Whisper ASR 모델 로드\n",
    "    logger.info(f\"Worker {thread_id} loaded Whisper model.\")\n",
    "\n",
    "    while True:  # 작업자가 계속 실행되도록 무한 루프\n",
    "        task_id, audio_path = task_queue.get()  # 큐에서 작업 가져오기\n",
    "        if task_id is None:  # 종료 신호 확인\n",
    "            break  # 종료 신호를 받으면 루프 종료\n",
    "        \n",
    "        logger.info(f\"Worker {thread_id} processing task {task_id}\")\n",
    "        \n",
    "        try:\n",
    "            # Whisper 모델을 사용하여 오디오 파일을 전사\n",
    "            results[task_id] = {\"status\": \"processing\"}\n",
    "            result = whisper_model.transcribe(audio_path)\n",
    "            # segment에서 id, start, end, text \n",
    "            # 비동기 \n",
    "            # API통신.uri(result, \"spring url\")\n",
    "            \n",
    "            \n",
    "            results[task_id] = {\"status\": \"completed\", \"result\": result}  # 결과를 딕셔너리에 저장\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Worker {thread_id} encountered an error: {str(e)}\")  # 발생한 오류 로그\n",
    "            results[task_id] = {\"status\": \"failed\", \"error\": str(e)}  # 오류를 결과에 저장\n",
    "        finally:\n",
    "            os.remove(audio_path)  # 임시 오디오 파일 제거\n",
    "            if torch.cuda.is_available():  # CUDA 사용 가능 여부 확인\n",
    "                torch.cuda.empty_cache()  # 필요 시 CUDA 메모리 캐시 지우기\n",
    "        \n",
    "        task_queue.task_done()  # 작업 완료 표시\n",
    "\n",
    "# 작업자 스레드 시작\n",
    "threads = []\n",
    "for i in range(num_worker_threads):\n",
    "    t = threading.Thread(target=worker, args=(i,))  # 작업자 함수에 대한 새 스레드 생성\n",
    "    t.start()  # 스레드 시작\n",
    "    threads.append(t)  # 스레드 목록에 추가\n",
    "\n",
    "@app.route('/', methods=['GET'])  # 홈 페이지를 위한 라우트 정의\n",
    "def home():\n",
    "    return \"Welcome to the Asynchronous Flask Server with Whisper!\"  # 환영 메시지 반환\n",
    "\n",
    "@app.route('/stt', methods=['POST'])  # STT 요청을 위한 라우트 정의\n",
    "def stt_request():\n",
    "    logger.info(\"Received STT request\")\n",
    "    \n",
    "    if 'audio' not in request.files:  # 오디오 파일이 제공되었는지 확인\n",
    "        logger.warning(\"No audio file provided in the request\")\n",
    "        return jsonify({'error': 'No audio file provided'}), 400  # 제공되지 않으면 오류 반환\n",
    "    \n",
    "    audio_data = request.files['audio']  # 요청에서 오디오 파일 가져오기\n",
    "    \n",
    "    if audio_data.filename == '':  # 파일 이름이 비어 있는지 확인\n",
    "        logger.warning(\"Empty filename provided\")\n",
    "        return jsonify({'error': 'No selected file'}), 400  # 비어 있으면 오류 반환\n",
    "    \n",
    "    logger.info(f\"Processing audio file: {audio_data.filename}\")\n",
    "    \n",
    "    # 오디오 데이터를 저장할 임시 파일 생성\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as temp_audio:\n",
    "        audio_data.save(temp_audio.name)  # 오디오 데이터를 임시 파일에 저장\n",
    "        temp_audio_path = temp_audio.name  # 임시 파일 경로 저장\n",
    "    \n",
    "    # 고유한 작업 ID를 생성하고 작업을 큐에 추가\n",
    "    task_id = str(audio_data.filename)  # 작업을 위한 고유 식별자 생성\n",
    "    task_queue.put((task_id, temp_audio_path))  # 큐에 작업 추가\n",
    "    \n",
    "    logger.info(f\"Task {task_id} added to the queue\")\n",
    "    \n",
    "    return jsonify({\"task_id\": task_id, \"status\": \"processing\"}), 202  # 작업 ID와 상태 반환\n",
    "\n",
    "@app.route('/stt_result/<task_id>', methods=['GET'])  # 작업 상태를 확인하기 위한 라우트 정의\n",
    "def get_status(task_id):\n",
    "    if task_id not in results:  # 작업 ID가 결과에 없으면\n",
    "        return jsonify({\"status\": \"No_result\"}), 404  # 처리 중 상태 반환\n",
    "    \n",
    "    result = results[task_id]  # 주어진 작업 ID에 대한 결과 가져오기\n",
    "    \n",
    "    if result[\"status\"] == \"completed\":  # 작업이 완료되었는지 확인\n",
    "        del results[task_id]  # 메모리 해제를 위해 결과 딕셔너리에서 제거\n",
    "        return jsonify(result), 200  # 완료된 결과 반환\n",
    "    elif result[\"status\"] == \"failed\":  # 작업이 실패했는지 확인\n",
    "        del results[task_id]  # 메모리 해제를 위해 결과 딕셔너리에서 제거\n",
    "        return jsonify(result), 500  # 실패한 결과 반환\n",
    "    else:\n",
    "        return jsonify({\"status\": \"processing\"}), 202  # 여전히 처리 중인 상태 반환\n",
    "\n",
    "@app.errorhandler(500)  # 500 내부 서버 오류 처리\n",
    "def internal_error(error):\n",
    "    logger.error(f\"Internal Server Error: {str(error)}\")  # 오류 로그\n",
    "    return jsonify({\"error\": \"Internal Server Error\"}), 500  # 오류 메시지 반환\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        app.run(host='0.0.0.0', port=5000)  # 포트 5000에서 Flask 앱 시작\n",
    "    finally:\n",
    "        # 애플리케이션 종료 시 작업자 스레드 중지\n",
    "        torch.cuda.empty_cache()  # 메모리 캐시 비우기\n",
    "        for _ in range(num_worker_threads):\n",
    "            task_queue.put((None, None))  # 스레드에 중지 신호 전송\n",
    "        for t in threads:\n",
    "            t.join()  # 모든 스레드가 종료될 때까지 대기\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
